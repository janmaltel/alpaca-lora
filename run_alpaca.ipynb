{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a70f09-83c3-45c8-83ce-f8540fa32c28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: accelerate==0.17.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate==0.17.0) (1.13.1)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate==0.17.0) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate==0.17.0) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate==0.17.0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate==0.17.0) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->accelerate==0.17.0) (3.0.9)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torch>=1.4.0->accelerate==0.17.0) (4.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: bitsandbytes==0.37.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.37.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: flexgen==0.1.7 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.1.7)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flexgen==0.1.7) (22.2.0)\n",
      "Requirement already satisfied: pulp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flexgen==0.1.7) (2.7.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flexgen==0.1.7) (1.23.5)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flexgen==0.1.7) (4.63.2)\n",
      "Requirement already satisfied: transformers>=4.24 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flexgen==0.1.7) (4.27.0.dev0)\n",
      "Requirement already satisfied: torch>=1.12 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flexgen==0.1.7) (1.13.1)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torch>=1.12->flexgen==0.1.7) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.24->flexgen==0.1.7) (5.4.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.24->flexgen==0.1.7) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.24->flexgen==0.1.7) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.24->flexgen==0.1.7) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.24->flexgen==0.1.7) (21.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.24->flexgen==0.1.7) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.24->flexgen==0.1.7) (0.13.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->transformers>=4.24->flexgen==0.1.7) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers>=4.24->flexgen==0.1.7) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers>=4.24->flexgen==0.1.7) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers>=4.24->flexgen==0.1.7) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers>=4.24->flexgen==0.1.7) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: gradio==3.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (3.18.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (1.23.5)\n",
      "Requirement already satisfied: markupsafe in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (2.1.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (1.4.4)\n",
      "Requirement already satisfied: httpx in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (0.23.3)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (0.94.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (2.28.1)\n",
      "Requirement already satisfied: aiofiles in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (23.1.0)\n",
      "Requirement already satisfied: python-multipart in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (0.0.6)\n",
      "Requirement already satisfied: pydantic in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (1.10.4)\n",
      "Requirement already satisfied: websockets>=10.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (10.4)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (3.1.2)\n",
      "Requirement already satisfied: uvicorn in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (0.21.0)\n",
      "Requirement already satisfied: altair>=4.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (4.2.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (2022.11.0)\n",
      "Requirement already satisfied: pydub in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (0.25.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (3.5.3)\n",
      "Requirement already satisfied: orjson in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (3.8.7)\n",
      "Requirement already satisfied: markdown-it-py[linkify,plugins]>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (2.2.0)\n",
      "Requirement already satisfied: pycryptodome in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (3.16.0)\n",
      "Requirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (9.2.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (5.4.1)\n",
      "Requirement already satisfied: ffmpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (0.3.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (4.4.0)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio==3.18.0) (3.8.3)\n",
      "Requirement already satisfied: entrypoints in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio==3.18.0) (0.4)\n",
      "Requirement already satisfied: toolz in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio==3.18.0) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio==3.18.0) (3.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from markdown-it-py[linkify,plugins]>=2.0.0->gradio==3.18.0) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from markdown-it-py[linkify,plugins]>=2.0.0->gradio==3.18.0) (2.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from markdown-it-py[linkify,plugins]>=2.0.0->gradio==3.18.0) (0.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->gradio==3.18.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->gradio==3.18.0) (2022.7)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio==3.18.0) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio==3.18.0) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio==3.18.0) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio==3.18.0) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio==3.18.0) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio==3.18.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio==3.18.0) (22.2.0)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from fastapi->gradio==3.18.0) (0.26.1)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpx->gradio==3.18.0) (1.5.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpx->gradio==3.18.0) (2022.12.7)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpx->gradio==3.18.0) (1.3.0)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpx->gradio==3.18.0) (0.16.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->gradio==3.18.0) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->gradio==3.18.0) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->gradio==3.18.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->gradio==3.18.0) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->gradio==3.18.0) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->gradio==3.18.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->gradio==3.18.0) (1.26.8)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from uvicorn->gradio==3.18.0) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from uvicorn->gradio==3.18.0) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio==3.18.0) (3.6.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.18.0) (0.19.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.18.0) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.18.0) (65.6.3)\n",
      "Requirement already satisfied: uc-micro-py in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.0.0->gradio==3.18.0) (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: rwkv==0.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.3.1)\n",
      "Requirement already satisfied: torch~=1.13.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from rwkv==0.3.1) (1.13.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from rwkv==0.3.1) (0.13.2)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torch~=1.13.1->rwkv==0.3.1) (4.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: safetensors==0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.1.97)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (4.63.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (2.10.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (4.63.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: responses<0.19 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (0.13.2)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting git+https://github.com/zphang/transformers@llama_push\n",
      "  Cloning https://github.com/zphang/transformers (to revision llama_push) to /tmp/pip-req-build-m845edvc\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/zphang/transformers /tmp/pip-req-build-m845edvc\n",
      "  Running command git checkout -b llama_push --track origin/llama_push\n",
      "  Switched to a new branch 'llama_push'\n",
      "  branch 'llama_push' set up to track 'origin/llama_push'.\n",
      "  Resolved https://github.com/zphang/transformers to commit ef61b1ba1a8ee9fd354b640b059c3474b676c0c5\n",
      "  Installing build dependencies ... \u001B[?25ldone\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.0.dev0) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.0.dev0) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.0.dev0) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.0.dev0) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.0.dev0) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.0.dev0) (4.63.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.0.dev0) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.27.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers==4.27.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers==4.27.0.dev0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers==4.27.0.dev0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers==4.27.0.dev0) (1.26.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate==0.17.0\n",
    "%pip install bitsandbytes==0.37.0\n",
    "%pip install flexgen==0.1.7\n",
    "%pip install gradio==3.18.0\n",
    "%pip install numpy\n",
    "%pip install requests\n",
    "%pip install rwkv==0.3.1\n",
    "%pip install safetensors==0.3.0\n",
    "%pip install sentencepiece\n",
    "%pip install tqdm\n",
    "%pip install datasets\n",
    "%pip install git+https://github.com/zphang/transformers@llama_push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b02384c-66fc-4b92-8d7a-a70185ef589f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import LLaMAForCausalLM, LLaMATokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4bf0cc-96be-4d4a-8ef8-2988fa5039d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfdd08-ec35-445c-abe5-355234a35c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.cuda.get_device_properties(0).total_memory\n",
    "# r = torch.cuda.memory_reserved(0)\n",
    "# a = torch.cuda.memory_allocated(0)\n",
    "# f = r-a  # free inside reserved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c89b4a-7a8d-43a3-9625-67b4c39d3ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Invalid device id",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_29635/21401996.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_device_properties\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/cuda/__init__.py\u001B[0m in \u001B[0;36mget_device_properties\u001B[0;34m(device)\u001B[0m\n\u001B[1;32m    372\u001B[0m     \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_device_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptional\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    373\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mdevice\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mdevice\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0mdevice_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 374\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mAssertionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Invalid device id\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    375\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0m_get_device_properties\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[name-defined]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: Invalid device id"
     ]
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3723647a-48d4-4d19-9488-d9a09aacc3ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007987499237060547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ebced33079349398c7f1cde4e3b68ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 15.78 GiB total capacity; 14.97 GiB already allocated; 86.94 MiB free; 14.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_29635/1047580734.py\u001B[0m in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mdevice_map\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"auto\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m )\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"cuda\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m tokenizer = LLaMATokenizer.from_pretrained(\n\u001B[1;32m     10\u001B[0m     \u001B[0;34m\"decapoda-research/llama-7b-hf\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_eos_token\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/modeling_utils.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1809\u001B[0m             )\n\u001B[1;32m   1810\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1811\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1812\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1813\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mhalf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    987\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    988\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 989\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    990\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    991\u001B[0m     def register_backward_hook(\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 641\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 641\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 641\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 641\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 641\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    662\u001B[0m             \u001B[0;31m# `with torch.no_grad():`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    663\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 664\u001B[0;31m                 \u001B[0mparam_applied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    665\u001B[0m             \u001B[0mshould_use_set_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    666\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mshould_use_set_data\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m    985\u001B[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001B[1;32m    986\u001B[0m                             non_blocking, memory_format=convert_to_format)\n\u001B[0;32m--> 987\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    988\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    989\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 15.78 GiB total capacity; 14.97 GiB already allocated; 86.94 MiB free; 14.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "load_in_8bit = False\n",
    "\n",
    "model = LLaMAForCausalLM.from_pretrained(\n",
    "    \"decapoda-research/llama-7b-hf\",\n",
    "    load_in_8bit=load_in_8bit,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model = model.to(\"cuda\")\n",
    "tokenizer = LLaMATokenizer.from_pretrained(\n",
    "    \"decapoda-research/llama-7b-hf\", add_eos_token=True\n",
    ")\n",
    "tokenizer.pad_token_id = 0  # unk. we want this to be different from the eos token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c18812b-75fe-4453-b525-4ac831650ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/ec2-user/.cache/huggingface/datasets/json/default-c6083352a35bf59d/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007584095001220703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6075f7f0f2436a83a2d006dcf2e8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52002\n"
     ]
    }
   ],
   "source": [
    "dataset = \"alpaca\"  # \"tiny\" or \"alpaca\"\n",
    "if dataset == \"tiny\":\n",
    "    data = load_from_disk(\"tiny_alpaca_data/\")\n",
    "elif dataset == \"alpaca\":\n",
    "    data = load_dataset(\"json\", data_files=\"alpaca_data.json\")\n",
    "print(len(data[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2548b08a-4509-4656-9e5e-826bce78f17d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 52002\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "505336f9-2a36-42b3-a93d-631f3e09b6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    # sorry about the formatting disaster gotta move fast\n",
    "    if data_point[\"input\"]:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "\n",
    "### Input:\n",
    "{data_point[\"input\"]}\n",
    "\n",
    "### Response:\n",
    "{data_point[\"output\"]}\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "\n",
    "### Response:\n",
    "{data_point[\"output\"]}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae8f6b3e-54a6-41dc-8f0c-d0b0dfa02850",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008231878280639648,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 52002,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot copy out of meta tensor; no data!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_18601/1076951818.py\u001B[0m in \u001B[0;36m<cell line: 18>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     16\u001B[0m )\n\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m trainer = transformers.Trainer(\n\u001B[0m\u001B[1;32m     19\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[0mtrain_dataset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"train\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/trainer.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001B[0m\n\u001B[1;32m    474\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    475\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplace_model_on_device\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"is_loaded_in_8bit\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 476\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_move_model_to_device\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    477\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    478\u001B[0m         \u001B[0;31m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/trainer.py\u001B[0m in \u001B[0;36m_move_model_to_device\u001B[0;34m(self, model, device)\u001B[0m\n\u001B[1;32m    713\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    714\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_move_model_to_device\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 715\u001B[0;31m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    716\u001B[0m         \u001B[0;31m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    717\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparallel_mode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mParallelMode\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTPU\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"tie_weights\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/modeling_utils.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1809\u001B[0m             )\n\u001B[1;32m   1810\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1811\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1812\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1813\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mhalf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    987\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    988\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 989\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    990\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    991\u001B[0m     def register_backward_hook(\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 641\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 641\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 641\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 641\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 641\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    662\u001B[0m             \u001B[0;31m# `with torch.no_grad():`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    663\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 664\u001B[0;31m                 \u001B[0mparam_applied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    665\u001B[0m             \u001B[0mshould_use_set_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    666\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mshould_use_set_data\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m    985\u001B[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001B[1;32m    986\u001B[0m                             non_blocking, memory_format=convert_to_format)\n\u001B[0;32m--> 987\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    988\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    989\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: Cannot copy out of meta tensor; no data!"
     ]
    }
   ],
   "source": [
    "# optimized for RTX 4090. for larger GPUs, increase some of these?\n",
    "MICRO_BATCH_SIZE = 4  # this could actually be 5 but i like powers of 2\n",
    "BATCH_SIZE = 128\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "EPOCHS = 1  # we don't need 3 tbh\n",
    "LEARNING_RATE = 3e-4  # the karpathy constant\n",
    "CUTOFF_LEN = 256  # 256 accounts for about 96% of the data\n",
    "\n",
    "data = data.shuffle().map(\n",
    "    lambda data_point: tokenizer(\n",
    "        generate_prompt(data_point),\n",
    "        truncation=True,\n",
    "        max_length=CUTOFF_LEN,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data[\"train\"],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
    "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "        warmup_steps=100,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir=\"pure-alpaca\",\n",
    "        save_total_limit=3,\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False\n",
    "trainer.train(resume_from_checkpoint=False)\n",
    "\n",
    "model.save_pretrained(\"pure-alpaca\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d6a11f6-6275-4602-9eea-48303112cb29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"Write a one-paragraph summary about Isaac Newton's mathematical discoveries.\",\n",
       " 'input': '',\n",
       " 'output': \"Sir Isaac Newton's mathematical discoveries revolutionized the way scientists think about the universe. He formulated the law of universal gravitation, which states that any two particles in the universe are attracted to one another by a force that is proportional to the product of their masses and inversely proportional to the square of their separation. He also developed calculus, which provides a mathematical description of how objects move. His work with optics and the refraction of light led him to develop the famous color wheel. His principles helped to establish the fields of kinematics and dynamics, and his laws are still used today to predict the trajectories of satellites and spacecraft.\",\n",
       " 'input_ids': [1,\n",
       "  13866,\n",
       "  338,\n",
       "  385,\n",
       "  15278,\n",
       "  393,\n",
       "  16612,\n",
       "  263,\n",
       "  3414,\n",
       "  29889,\n",
       "  14350,\n",
       "  263,\n",
       "  2933,\n",
       "  393,\n",
       "  7128,\n",
       "  2486,\n",
       "  1614,\n",
       "  2167,\n",
       "  278,\n",
       "  2009,\n",
       "  29889,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  2799,\n",
       "  4080,\n",
       "  29901,\n",
       "  13,\n",
       "  6113,\n",
       "  263,\n",
       "  697,\n",
       "  29899,\n",
       "  26956,\n",
       "  15837,\n",
       "  1048,\n",
       "  28156,\n",
       "  19017,\n",
       "  29915,\n",
       "  29879,\n",
       "  19475,\n",
       "  6523,\n",
       "  583,\n",
       "  29889,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  13291,\n",
       "  29901,\n",
       "  13,\n",
       "  29903,\n",
       "  381,\n",
       "  28156,\n",
       "  19017,\n",
       "  29915,\n",
       "  29879,\n",
       "  19475,\n",
       "  6523,\n",
       "  583,\n",
       "  19479,\n",
       "  1891,\n",
       "  278,\n",
       "  982,\n",
       "  9638,\n",
       "  2879,\n",
       "  1348,\n",
       "  1048,\n",
       "  278,\n",
       "  19859,\n",
       "  29889,\n",
       "  940,\n",
       "  883,\n",
       "  7964,\n",
       "  278,\n",
       "  4307,\n",
       "  310,\n",
       "  15968,\n",
       "  8310,\n",
       "  7018,\n",
       "  29892,\n",
       "  607,\n",
       "  5922,\n",
       "  393,\n",
       "  738,\n",
       "  1023,\n",
       "  17105,\n",
       "  297,\n",
       "  278,\n",
       "  19859,\n",
       "  526,\n",
       "  13978,\n",
       "  287,\n",
       "  304,\n",
       "  697,\n",
       "  1790,\n",
       "  491,\n",
       "  263,\n",
       "  4889,\n",
       "  393,\n",
       "  338,\n",
       "  29839,\n",
       "  304,\n",
       "  278,\n",
       "  3234,\n",
       "  310,\n",
       "  1009,\n",
       "  23063,\n",
       "  322,\n",
       "  297,\n",
       "  874,\n",
       "  873,\n",
       "  29839,\n",
       "  304,\n",
       "  278,\n",
       "  6862,\n",
       "  310,\n",
       "  1009,\n",
       "  23683,\n",
       "  29889,\n",
       "  940,\n",
       "  884,\n",
       "  8906,\n",
       "  24282,\n",
       "  29892,\n",
       "  607,\n",
       "  8128,\n",
       "  263,\n",
       "  19475,\n",
       "  6139,\n",
       "  310,\n",
       "  920,\n",
       "  3618,\n",
       "  4337,\n",
       "  29889,\n",
       "  3600,\n",
       "  664,\n",
       "  411,\n",
       "  3523,\n",
       "  1199,\n",
       "  322,\n",
       "  278,\n",
       "  2143,\n",
       "  13857,\n",
       "  310,\n",
       "  3578,\n",
       "  5331,\n",
       "  1075,\n",
       "  304,\n",
       "  2693,\n",
       "  278,\n",
       "  13834,\n",
       "  2927,\n",
       "  18875,\n",
       "  29889,\n",
       "  3600,\n",
       "  18671,\n",
       "  9213,\n",
       "  304,\n",
       "  10127,\n",
       "  278,\n",
       "  4235,\n",
       "  310,\n",
       "  19015,\n",
       "  4579,\n",
       "  1199,\n",
       "  322,\n",
       "  19753,\n",
       "  29892,\n",
       "  322,\n",
       "  670,\n",
       "  14243,\n",
       "  526,\n",
       "  1603,\n",
       "  1304,\n",
       "  9826,\n",
       "  304,\n",
       "  8500,\n",
       "  278,\n",
       "  23324,\n",
       "  3842,\n",
       "  310,\n",
       "  3290,\n",
       "  514,\n",
       "  3246,\n",
       "  322,\n",
       "  2913,\n",
       "  17293,\n",
       "  29889,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab908b6c-d476-4618-891b-87f7595eec09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Write a poem about the following topic.\n",
    "\n",
    "### Input:\n",
    "Cars\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "    PROMPT,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "generation_output = model.generate(\n",
    "    **inputs, return_dict_in_generate=True, output_scores=True, max_new_tokens=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46c91b27-b529-4a5f-815d-861abed7f6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Write a poem about the following topic.\n",
      "\n",
      "### Input:\n",
      "Cars\n",
      "\n",
      "### Response:\n"
     ]
    }
   ],
   "source": [
    "for s in generation_output.sequences:\n",
    "    print(tokenizer.decode(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2eae60d-152f-4387-ac78-f6a0f554b3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 13866,   338,   385, 15278,   393, 16612,   263,  3414, 29892,\n",
       "          3300,  2859,   411,   385,  1881,   393,  8128,  4340,  3030, 29889,\n",
       "         14350,   263,  2933,   393,  7128,  2486,  1614,  2167,   278,  2009,\n",
       "         29889,    13,    13,  2277, 29937,  2799,  4080, 29901,    13,  6113,\n",
       "           263, 26576,  1048,   278,  1494, 11261, 29889,    13,    13,  2277,\n",
       "         29937, 10567, 29901,    13, 29907,  1503,    13,    13,  2277, 29937,\n",
       "         13291, 29901,     2,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_output.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83102e42-9d06-475b-b8c2-7fc2635020cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\" == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "726be96d-bc06-406b-bd23-858d2316953c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla\n"
     ]
    }
   ],
   "source": [
    "if \"sd\":\n",
    "    print(\"bla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb773743-c501-4641-bb41-cca28a38531f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
